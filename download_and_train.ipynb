{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff46769",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86023d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataset_functions as df\n",
    "import utils.user_features as uf\n",
    "import utils.two_towers as ttn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm as progress_bar\n",
    "\n",
    "\n",
    "(Path(\"dataset\") / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "data_dir = Path(\"dataset\") / \"unprocessed\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3677651",
   "metadata": {},
   "source": [
    "## 1. Download and write locally to CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write files locally\n",
    "dataset_types = [\"likes\", \"listens\", \"dislikes\", \"unlikes\", \"undislikes\"]\n",
    "dataset = df.YambdaDataset('flat', '50m')\n",
    "for dt in dataset_types:\n",
    "    df.download_df(dataset=dataset, dataset_type=dt)\n",
    "\n",
    "\n",
    "if not (data_dir / \"embeddings.csv\").exists():\n",
    "    embeddings = dataset.audio_embeddings().to_pandas()\n",
    "    embeddings.to_csv(data_dir / \"embeddings.csv\", index=False)\n",
    "    del embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed24dc2",
   "metadata": {},
   "source": [
    "## 2. Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501c8667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>is_organic</th>\n",
       "      <th>played_ratio_pct</th>\n",
       "      <th>track_length_seconds</th>\n",
       "      <th>normalized_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>39420</td>\n",
       "      <td>8326270</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>170</td>\n",
       "      <td>[-0.169998115, -0.0959603293, 0.0354052303, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>39420</td>\n",
       "      <td>1441281</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>[-0.11168661, -0.06717089, -0.01324262, -0.075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>39625</td>\n",
       "      <td>286361</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>185</td>\n",
       "      <td>[-0.08362152, 0.01492759, 0.04177505, -0.07362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>40110</td>\n",
       "      <td>732449</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>[-0.09272503, 0.00863106, 0.00500664, -0.07165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>40360</td>\n",
       "      <td>3397170</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>[0.00739911, 0.02237171, -0.05895943, -0.04705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606652</th>\n",
       "      <td>999900</td>\n",
       "      <td>25757935</td>\n",
       "      <td>7156502</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>155</td>\n",
       "      <td>[-0.03618009, -0.01209565, -0.04070508, 0.0260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606653</th>\n",
       "      <td>999900</td>\n",
       "      <td>25758105</td>\n",
       "      <td>3117997</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>195</td>\n",
       "      <td>[-0.13640163, 0.09070778, -0.11365859, -0.0977...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606654</th>\n",
       "      <td>999900</td>\n",
       "      <td>25777330</td>\n",
       "      <td>9224219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>[-0.17506402, -0.07690737, -0.09771042, -0.106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606655</th>\n",
       "      <td>999900</td>\n",
       "      <td>25777360</td>\n",
       "      <td>8192914</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>155</td>\n",
       "      <td>[-0.0344837197, 0.0172222336, 0.00892607541, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606656</th>\n",
       "      <td>999900</td>\n",
       "      <td>25777525</td>\n",
       "      <td>7227266</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>160</td>\n",
       "      <td>[-0.02479589, -0.08885409, 0.00972836, -0.0035...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9606657 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            uid  timestamp  item_id  is_organic  played_ratio_pct  \\\n",
       "0           100      39420  8326270           0               100   \n",
       "1           100      39420  1441281           0               100   \n",
       "2           100      39625   286361           0               100   \n",
       "3           100      40110   732449           0               100   \n",
       "4           100      40360  3397170           0                46   \n",
       "...         ...        ...      ...         ...               ...   \n",
       "9606652  999900   25757935  7156502           0               100   \n",
       "9606653  999900   25758105  3117997           0                51   \n",
       "9606654  999900   25777330  9224219           1                 0   \n",
       "9606655  999900   25777360  8192914           1                15   \n",
       "9606656  999900   25777525  7227266           1               100   \n",
       "\n",
       "         track_length_seconds  \\\n",
       "0                         170   \n",
       "1                         105   \n",
       "2                         185   \n",
       "3                         240   \n",
       "4                         130   \n",
       "...                       ...   \n",
       "9606652                   155   \n",
       "9606653                   195   \n",
       "9606654                   295   \n",
       "9606655                   155   \n",
       "9606656                   160   \n",
       "\n",
       "                                          normalized_embed  \n",
       "0        [-0.169998115, -0.0959603293, 0.0354052303, -0...  \n",
       "1        [-0.11168661, -0.06717089, -0.01324262, -0.075...  \n",
       "2        [-0.08362152, 0.01492759, 0.04177505, -0.07362...  \n",
       "3        [-0.09272503, 0.00863106, 0.00500664, -0.07165...  \n",
       "4        [0.00739911, 0.02237171, -0.05895943, -0.04705...  \n",
       "...                                                    ...  \n",
       "9606652  [-0.03618009, -0.01209565, -0.04070508, 0.0260...  \n",
       "9606653  [-0.13640163, 0.09070778, -0.11365859, -0.0977...  \n",
       "9606654  [-0.17506402, -0.07690737, -0.09771042, -0.106...  \n",
       "9606655  [-0.0344837197, 0.0172222336, 0.00892607541, 0...  \n",
       "9606656  [-0.02479589, -0.08885409, 0.00972836, -0.0035...  \n",
       "\n",
       "[9606657 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User like-dislike interactions\n",
    "likes = pd.read_csv(data_dir / \"likes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "dislikes = pd.read_csv(data_dir / \"dislikes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "unlikes = pd.read_csv(data_dir / \"unlikes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "undislikes = pd.read_csv(data_dir / \"dislikes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "\n",
    "# If not done before\n",
    "if (Path(\"dataset\") / \"processed\" / \"merged.csv\").exists():\n",
    "    user_item_data = pd.read_csv(Path(\"dataset\") / \"processed\" / \"merged.csv\", index_col=False)\n",
    "    user_item_data[\"normalized_embed\"] = user_item_data[\"normalized_embed\"].apply(df.parse_embedding)\n",
    "\n",
    "else:\n",
    "    # User listen interactions\n",
    "    listens = pd.read_csv(data_dir / \"listens.csv\", index_col=False)\n",
    "    listens.drop(columns=['is_organic'])\n",
    "\n",
    "    # due to computational limitations, we constrain our dataset to users to have between 500 and 5000 timestamps.\n",
    "    listens = listens.groupby('uid').filter(lambda x: 500 <= len(x) <= 5000)\n",
    "\n",
    "    # Embeddings\n",
    "    embeddings = pd.read_csv(data_dir/'embeddings.csv', usecols=['item_id', 'normalized_embed'], index_col=False)\n",
    "    embeddings[\"normalized_embed\"] = embeddings[\"normalized_embed\"].apply(df.parse_embedding)\n",
    "\n",
    "    # Merge the song embeddings and user listens dataset \n",
    "    user_item_data = pd.merge(listens, embeddings, on='item_id', how='inner')\n",
    "    \n",
    "    \n",
    "    # save memory\n",
    "    del listens\n",
    "    del embeddings\n",
    "\n",
    "    # Determine the labels under different conditions using this function.\n",
    "    user_item_data[[\"labels\", \"net_interactions\"]] = user_item_data.apply(\n",
    "    uf.get_song_label_and_user_interacton,\n",
    "    axis=1,\n",
    "    args=(likes, user_item_data, unlikes, dislikes, undislikes),\n",
    "    result_type=\"expand\") \n",
    "\n",
    "    # Save our processed dataset.\n",
    "    user_item_data.to_csv(Path(\"dataset\") / \"processed\" / \"merged.csv\", index=False)\n",
    "\n",
    "user_item_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc209db",
   "metadata": {},
   "source": [
    "## 3. Create and save user features\n",
    "We do this in train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be1e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1106ff4ba58440229cb97c1e01cdd9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e883a59376e54e15924d0300f3ada76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480f2922b7504f5883c059418aa00aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "users = user_item_data['uid'].unique()\n",
    "\n",
    "# It is HIGHLY recommended to use more than 1 thread per set\n",
    "# You can split the data equally over threads like so:\n",
    "\n",
    "todo_users = [u for u in users if not (Path(\"dataset\")/ \"processed\" / \"users\"/ f\"{u}.pt\").exists()]\n",
    "num_threads = 14\n",
    "k, m = divmod(len(todo_users), num_threads)\n",
    "user_split = [todo_users[i*k + min(i, m) : (i+1)*k + min(i+1, m)] for i in range(num_threads)]\n",
    "\n",
    "\n",
    "\n",
    "# Multithread it to make it somewhat time managable\n",
    "t1 = Thread(target=uf.extract_and_save_features, args=(user_split[0], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, unlikes, dislikes, undislikes))\n",
    "t2 = Thread(target=uf.extract_and_save_features, args=(user_split[1], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, unlikes, dislikes, undislikes))\n",
    "t3 = Thread(target=uf.extract_and_save_features, args=(user_split[2], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, unlikes, dislikes, undislikes))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1313d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory, we don't need this anymore\n",
    "del user_item_data \n",
    "del likes\n",
    "del dislikes\n",
    "del unlikes\n",
    "del undislikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888d341",
   "metadata": {},
   "source": [
    "### 3.1: merge the seperate user files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1eabb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c55f9b33a14992bd459f4d78d53a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing users:   0%|          | 0/4457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6660158\n",
      "Val size:   1427629\n",
      "Test size:  1429730\n"
     ]
    }
   ],
   "source": [
    "files = Path(\"dataset\") / \"processed\" / \"users\"\n",
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "\n",
    "\n",
    "train_feats = []\n",
    "train_ids = []\n",
    "train_embeds = []\n",
    "train_labels = []\n",
    "train_interactions = []\n",
    "\n",
    "val_feats = []\n",
    "val_ids = []\n",
    "val_embeds = []\n",
    "val_labels = []\n",
    "val_interactions = []\n",
    "\n",
    "test_feats = []\n",
    "test_ids = []\n",
    "test_embeds = []\n",
    "test_labels = []\n",
    "test_interactions = []\n",
    "\n",
    "files = list(files.glob(\"*.pt\"))\n",
    "\n",
    "for file in progress_bar(files, desc=\"Processing users\"):\n",
    "    data = torch.load(file, map_location=\"cpu\")\n",
    "\n",
    "    feats = data['user_feats']         # shape: [N, F]\n",
    "    user_ids = data['user_ids']        # shape: [N]\n",
    "    embeds = data['song_embeds']       # shape: [N, E]\n",
    "    labels = data['labels']            # shape: [N, L]\n",
    "    interactions = data['interactions'] # shape: [N]\n",
    "\n",
    "    N = feats.shape[0]\n",
    "\n",
    "    # ---- Split indices ----\n",
    "    train_end = int(N * 0.70)\n",
    "    val_end   = int(N * 0.85)\n",
    "\n",
    "    # ---- Slice per user ----\n",
    "    feats_train = feats[:train_end]\n",
    "    feats_val   = feats[train_end:val_end]\n",
    "    feats_test  = feats[val_end:]\n",
    "\n",
    "    ids_train = user_ids[:train_end]\n",
    "    ids_val   = user_ids[train_end:val_end]\n",
    "    ids_test  = user_ids[val_end:]\n",
    "\n",
    "    embeds_train = embeds[:train_end]\n",
    "    embeds_val   = embeds[train_end:val_end]\n",
    "    embeds_test  = embeds[val_end:]\n",
    "\n",
    "    labels_train = labels[:train_end]\n",
    "    labels_val   = labels[train_end:val_end]\n",
    "    labels_test  = labels[val_end:]\n",
    "\n",
    "    inter_train = interactions[:train_end]\n",
    "    inter_val   = interactions[train_end:val_end]\n",
    "    inter_test  = interactions[val_end:]\n",
    "\n",
    "    # ---- Append to global lists ----\n",
    "    train_feats.append(feats_train)\n",
    "    train_ids.append(ids_train)\n",
    "    train_embeds.append(embeds_train)\n",
    "    train_labels.append(labels_train)\n",
    "    train_interactions.append(inter_train)\n",
    "\n",
    "    val_feats.append(feats_val)\n",
    "    val_ids.append(ids_val)\n",
    "    val_embeds.append(embeds_val)\n",
    "    val_labels.append(labels_val)\n",
    "    val_interactions.append(inter_val)\n",
    "\n",
    "    test_feats.append(feats_test)\n",
    "    test_ids.append(ids_test)\n",
    "    test_embeds.append(embeds_test)\n",
    "    test_labels.append(labels_test)\n",
    "    test_interactions.append(inter_test)\n",
    "\n",
    "# ---- Final merge ----\n",
    "train = {\n",
    "    \"user_feats\": torch.cat(train_feats, dim=0),\n",
    "    \"user_ids\": torch.cat(train_ids, dim=0),\n",
    "    \"song_embeds\": torch.cat(train_embeds, dim=0),\n",
    "    \"labels\": torch.cat(train_labels, dim=0),\n",
    "    \"interactions\": torch.cat(train_interactions, dim=0),\n",
    "}\n",
    "\n",
    "val = {\n",
    "    \"user_feats\": torch.cat(val_feats, dim=0),\n",
    "    \"user_ids\": torch.cat(val_ids, dim=0),\n",
    "    \"song_embeds\": torch.cat(val_embeds, dim=0),\n",
    "    \"labels\": torch.cat(val_labels, dim=0),\n",
    "    \"interactions\": torch.cat(val_interactions, dim=0),\n",
    "}\n",
    "\n",
    "test = {\n",
    "    \"user_feats\": torch.cat(test_feats, dim=0),\n",
    "    \"user_ids\": torch.cat(test_ids, dim=0),\n",
    "    \"song_embeds\": torch.cat(test_embeds, dim=0),\n",
    "    \"labels\": torch.cat(test_labels, dim=0),\n",
    "    \"interactions\": torch.cat(test_interactions, dim=0),\n",
    "}\n",
    "\n",
    "print(\"Train size:\", train[\"user_feats\"].shape[0])\n",
    "print(\"Val size:  \", val[\"user_feats\"].shape[0])\n",
    "print(\"Test size: \", test[\"user_feats\"].shape[0])\n",
    "\n",
    "torch.save(train, Path(\"dataset\") / \"processed\" / \"train.pt\")\n",
    "torch.save(val, Path(\"dataset\") / \"processed\" / \"val.pt\")\n",
    "torch.save(test, Path(\"dataset\") / \"processed\" / \"test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b56b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_set = df.load_tensor_dataloader(\"subset\", Path(\"dataset\")/\"processed\", batch_size=64)\n",
    "for user_feats, song_embeds, labels, interactions in train_set:\n",
    "    print(user_feats.shape)\n",
    "    print(song_embeds.shape)\n",
    "    print(labels.shape)\n",
    "    print(interactions.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194c838",
   "metadata": {},
   "source": [
    "## 4. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f598ad8",
   "metadata": {},
   "source": [
    "### 4.1 set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d528b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataset_functions as df\n",
    "import utils.user_features as uf\n",
    "import utils.two_towers as ttn\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm as progress_bar\n",
    "\n",
    "\n",
    "(Path(\"dataset\") / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "data_dir = Path(\"dataset\") / \"unprocessed\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "# Input dimensions\n",
    "user_dim        = 5 #+ 129  # user_features + label specific features\n",
    "item_dim        = 128\n",
    "aug_dim         = 32\n",
    "\n",
    "# Dimensions of the tower FFN\n",
    "hidden_dim      = 64\n",
    "embed_dim       = 32\n",
    "\n",
    "# lambda1 for loss_u & lambda2 for loss_V\n",
    "lambda1         = 1\n",
    "lambda2         = 1\n",
    "\n",
    "# Training\n",
    "num_epochs      = 50\n",
    "learning_rate   = 1e-3\n",
    "batch_size      = 128\n",
    "patience        = 5\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Training models on:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32021d74",
   "metadata": {},
   "source": [
    "### 4.2 Training our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df.load_tensor_dataloader(\"train\", Path(\"dataset\")/\"processed\", batch_size, 0)\n",
    "val_set = df.load_tensor_dataloader(\"val\", Path(\"dataset\")/\"processed\", batch_size, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"interactions_model\", \"multiple_listens_model\", \"pct_100_model\", \"pct_80_model\"]\n",
    "\n",
    "for label_id, model_name in enumerate(models[1:]):\n",
    "    train_set = df.load_tensor_dataloader(\"train\", Path(\"dataset\")/\"processed\", batch_size, label_id)\n",
    "    val_set = df.load_tensor_dataloader(\"val\", Path(\"dataset\")/\"processed\", batch_size, label_id)\n",
    "\n",
    "\n",
    "    model = ttn.DualAugmentedTwoTower(model_name, user_dim, item_dim, hidden_dim, aug_dim)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    ttn.train_model(model, train_set, val_set, optimiser, patience, num_epochs=num_epochs, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df.load_tensor_dataloader(\"test\", Path(\"dataset\")/\"processed\", batch_size, 0)\n",
    "\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_features, song_embedding, labels, interactions in test_set:\n",
    "        # Move to device\n",
    "        user_features = user_features.to(device)\n",
    "        song_embedding = song_embedding.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        scores, pu, pv = model(user_features, song_embedding)\n",
    "\n",
    "        # Loss\n",
    "        loss = model.loss(scores, pu, pv, labels, lambda1, lambda2)\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        # ----- ACCURACY -----\n",
    "        # If labels are 0/1 → typical classification\n",
    "        preds = (scores >= 0.95).long()      # threshold for binary classification\n",
    "        correct = (preds.squeeze() == labels.long()).sum().item()\n",
    "\n",
    "        total_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "# Final metrics\n",
    "avg_loss = total_loss / total_samples\n",
    "accuracy = total_correct / total_samples\n",
    "\n",
    "print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
