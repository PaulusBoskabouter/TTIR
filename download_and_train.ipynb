{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff46769",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86023d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataset_functions as df\n",
    "import utils.user_features as uf\n",
    "import utils.two_towers as ttn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from threading import Thread\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm as progress_bar\n",
    "\n",
    "\n",
    "(Path(\"dataset\") / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "data_dir = Path(\"dataset\") / \"unprocessed\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3677651",
   "metadata": {},
   "source": [
    "## 1. Download and write locally to CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349e9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write files locally\n",
    "dataset_types = [\"likes\", \"listens\", \"dislikes\", \"unlikes\", \"undislikes\"]\n",
    "dataset = df.YambdaDataset('flat', '50m')\n",
    "for dt in dataset_types:\n",
    "    df.download_df(dataset=dataset, dataset_type=dt)\n",
    "\n",
    "\n",
    "if not (data_dir / \"embeddings.csv\").exists():\n",
    "    embeddings = dataset.audio_embeddings().to_pandas()\n",
    "    embeddings.to_csv(data_dir / \"embeddings.csv\", index=False)\n",
    "    del embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed24dc2",
   "metadata": {},
   "source": [
    "## 2. Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c8667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>played_ratio_pct</th>\n",
       "      <th>track_length_seconds</th>\n",
       "      <th>normalized_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39420</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>170</td>\n",
       "      <td>[-0.169998115, -0.0959603293, 0.0354052303, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40380</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>205</td>\n",
       "      <td>[-0.13720872, -0.07012163, -0.05605687, -0.220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40640</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>205</td>\n",
       "      <td>[-0.201428336, -0.0348165734, -0.115619186, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>41130</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>245</td>\n",
       "      <td>[-0.08191244, -0.0886203, -0.09830238, -0.1605...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>42115</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>[-0.0704478517, -0.0471708378, -0.0264391324, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880035</th>\n",
       "      <td>5425</td>\n",
       "      <td>25961230</td>\n",
       "      <td>979</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>[-0.13856041, 0.07792329, -0.08014846, -0.0198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880036</th>\n",
       "      <td>5425</td>\n",
       "      <td>25961615</td>\n",
       "      <td>1117</td>\n",
       "      <td>99</td>\n",
       "      <td>200</td>\n",
       "      <td>[-0.1448793, 0.08461289, 0.02028048, 0.0217482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880037</th>\n",
       "      <td>5425</td>\n",
       "      <td>25961805</td>\n",
       "      <td>1054</td>\n",
       "      <td>99</td>\n",
       "      <td>190</td>\n",
       "      <td>[-0.0609348332, 0.0349645983, -0.0275787699, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880038</th>\n",
       "      <td>5425</td>\n",
       "      <td>25962060</td>\n",
       "      <td>1629</td>\n",
       "      <td>100</td>\n",
       "      <td>255</td>\n",
       "      <td>[0.0730053227, 0.0352250292, 0.0868287894, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880039</th>\n",
       "      <td>5425</td>\n",
       "      <td>25962225</td>\n",
       "      <td>927</td>\n",
       "      <td>74</td>\n",
       "      <td>220</td>\n",
       "      <td>[-0.17286014, 0.07140227, 0.0137846, -0.094523...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3880040 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid  timestamp  item_id  played_ratio_pct  track_length_seconds  \\\n",
       "0           0      39420        0               100                   170   \n",
       "1           0      40380        1               100                   205   \n",
       "2           0      40640        2               100                   205   \n",
       "3           0      41130        3               100                   245   \n",
       "4           0      42115        4                 1                   200   \n",
       "...       ...        ...      ...               ...                   ...   \n",
       "3880035  5425   25961230      979               100                   200   \n",
       "3880036  5425   25961615     1117                99                   200   \n",
       "3880037  5425   25961805     1054                99                   190   \n",
       "3880038  5425   25962060     1629               100                   255   \n",
       "3880039  5425   25962225      927                74                   220   \n",
       "\n",
       "                                          normalized_embed  \n",
       "0        [-0.169998115, -0.0959603293, 0.0354052303, -0...  \n",
       "1        [-0.13720872, -0.07012163, -0.05605687, -0.220...  \n",
       "2        [-0.201428336, -0.0348165734, -0.115619186, -0...  \n",
       "3        [-0.08191244, -0.0886203, -0.09830238, -0.1605...  \n",
       "4        [-0.0704478517, -0.0471708378, -0.0264391324, ...  \n",
       "...                                                    ...  \n",
       "3880035  [-0.13856041, 0.07792329, -0.08014846, -0.0198...  \n",
       "3880036  [-0.1448793, 0.08461289, 0.02028048, 0.0217482...  \n",
       "3880037  [-0.0609348332, 0.0349645983, -0.0275787699, 0...  \n",
       "3880038  [0.0730053227, 0.0352250292, 0.0868287894, 0.0...  \n",
       "3880039  [-0.17286014, 0.07140227, 0.0137846, -0.094523...  \n",
       "\n",
       "[3880040 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If not done before\n",
    "if (Path(\"dataset\") / \"processed\" / \"merged.csv\").exists():\n",
    "    user_item_data = pd.read_csv(Path(\"dataset\") / \"processed\" / \"merged.csv\", index_col=False)\n",
    "    user_item_data[\"normalized_embed\"] = user_item_data[\"normalized_embed\"].apply(df.parse_embedding)\n",
    "    # User like-dislike interactions\n",
    "    likes = pd.read_csv(Path(\"dataset\") / \"processed\" / \"likes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "    dislikes = pd.read_csv(Path(\"dataset\") / \"processed\" / \"dislikes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "\n",
    "else:\n",
    "    # User listen interactions\n",
    "    listens = pd.read_csv(data_dir / \"listens.csv\", index_col=False)\n",
    "    listens[listens[\"is_organic\"] == 1]\n",
    "    listens.drop(\"is_organic\", axis=1, inplace=True)\n",
    "\n",
    "    # User like-dislike interactions\n",
    "    cols = [\"uid\", \"timestamp\", \"item_id\"]\n",
    "\n",
    "\n",
    "    likes = pd.read_csv(data_dir / \"likes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "    dislikes = pd.read_csv(data_dir / \"dislikes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "    unlikes = pd.read_csv(data_dir / \"unlikes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "    undislikes = pd.read_csv(data_dir / \"undislikes.csv\", usecols=['uid', 'timestamp', 'item_id'])\n",
    "\n",
    "\n",
    "    # due to computational limitations, we constrain our dataset to users to have between 500 and 5000 timestamps.\n",
    "    listens = listens.groupby('uid').filter(lambda x: 100 <= len(x) <=5000)\n",
    "    # We only take data containing songs that appear at least a 1000 times in the interaction dataset\n",
    "    cut_off = 500\n",
    "    counts = listens['item_id'].value_counts()\n",
    "    temp = []\n",
    "    for id, count in counts.items():\n",
    "        if count >= cut_off:\n",
    "            temp.append(id)\n",
    "    listens  = listens[listens['item_id'].isin(temp)]\n",
    "    \n",
    "\n",
    "    # Embeddings\n",
    "    embeddings = pd.read_csv(data_dir/'embeddings.csv', usecols=['item_id', 'normalized_embed'], index_col=False)\n",
    "    embeddings[\"normalized_embed\"] = embeddings[\"normalized_embed\"].apply(df.parse_embedding)\n",
    "\n",
    "    # Merge the song embeddings and user listens dataset \n",
    "    user_item_data = pd.merge(listens, embeddings, on='item_id', how='inner')\n",
    "\n",
    "    valid_items = user_item_data['item_id'].unique()\n",
    "    likes  = likes[likes['item_id'].isin(valid_items)]\n",
    "    dislikes  = dislikes[dislikes['item_id'].isin(valid_items)]\n",
    "    unlikes  = unlikes[unlikes['item_id'].isin(valid_items)]\n",
    "    undislikes  = undislikes[undislikes['item_id'].isin(valid_items)]\n",
    "\n",
    "    # Filter rows in liked that are unliked and rows in disliked that are in undisliked\n",
    "    likes = likes[~likes.set_index(cols).index.isin(unlikes.set_index(cols).index)].reset_index(drop=True).drop_duplicates()\n",
    "    dislikes = dislikes[~dislikes.set_index(cols).index.isin(undislikes.set_index(cols).index)].reset_index(drop=True).drop_duplicates()\n",
    "\n",
    "\n",
    "    # save memory\n",
    "    del listens\n",
    "    del embeddings\n",
    "    del temp\n",
    "    del unlikes\n",
    "    del undislikes\n",
    "\n",
    "\n",
    "    uid_map = {}\n",
    "\n",
    "    for id, uid in enumerate(user_item_data['uid'].unique()):\n",
    "        uid_map[uid] = id\n",
    "\n",
    "    item_id_map = {}\n",
    "    for id, sid in enumerate(user_item_data['item_id'].unique()):\n",
    "        item_id_map[sid] = id\n",
    "    \n",
    "    \n",
    "    \n",
    "    user_item_data['uid'] = user_item_data[\"uid\"].replace(uid_map)\n",
    "    user_item_data['item_id'] = user_item_data[\"item_id\"].replace(item_id_map)\n",
    "\n",
    "    likes['uid'] = likes[\"uid\"].replace(uid_map)\n",
    "    likes['item_id'] = likes[\"item_id\"].replace(item_id_map)\n",
    "\n",
    "    dislikes['uid'] = dislikes[\"uid\"].replace(uid_map)\n",
    "    dislikes['item_id'] = dislikes[\"item_id\"].replace(item_id_map)\n",
    "\n",
    "\n",
    "    # Convert array column to a hashable type\n",
    "    df = user_item_data.copy()\n",
    "    df['normalized_embed_tuple'] = df['normalized_embed'].apply(lambda x: tuple(x))\n",
    "\n",
    "    # Keep only unique rows based on item_id + embed\n",
    "    df_unique = df.drop_duplicates(subset=['item_id', 'normalized_embed_tuple'])\n",
    "\n",
    "    # Keep only the original two columns\n",
    "    df_unique = df_unique[['item_id', 'normalized_embed']]\n",
    "\n",
    "\n",
    "    # Save our processed dataset.\n",
    "    user_item_data.to_csv(Path(\"dataset\") / \"processed\" / \"merged.csv\", index=False)\n",
    "    likes.to_csv(Path(\"dataset\") / \"processed\" / \"likes.csv\", index=False)\n",
    "    dislikes.to_csv(Path(\"dataset\") / \"processed\" / \"dislikes.csv\", index=False)\n",
    "\n",
    "\n",
    "user_item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afaf9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3939350</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6903355</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10314390</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23471875</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>23540595</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247535</th>\n",
       "      <td>5424</td>\n",
       "      <td>19821670</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247536</th>\n",
       "      <td>5424</td>\n",
       "      <td>24634975</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247537</th>\n",
       "      <td>5424</td>\n",
       "      <td>25710740</td>\n",
       "      <td>2924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247538</th>\n",
       "      <td>5425</td>\n",
       "      <td>14299485</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247539</th>\n",
       "      <td>5425</td>\n",
       "      <td>19336945</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247540 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid  timestamp  item_id\n",
       "0          0    3939350       49\n",
       "1          0    6903355       52\n",
       "2          0   10314390       63\n",
       "3          0   23471875      171\n",
       "4          0   23540595       93\n",
       "...      ...        ...      ...\n",
       "247535  5424   19821670     1228\n",
       "247536  5424   24634975       11\n",
       "247537  5424   25710740     2924\n",
       "247538  5425   14299485     1354\n",
       "247539  5425   19336945      770\n",
       "\n",
       "[247540 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54ab3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>5519800</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800</td>\n",
       "      <td>5668430</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800</td>\n",
       "      <td>10649375</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800</td>\n",
       "      <td>12673195</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800</td>\n",
       "      <td>13626180</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28328</th>\n",
       "      <td>5420</td>\n",
       "      <td>13508230</td>\n",
       "      <td>2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28329</th>\n",
       "      <td>5420</td>\n",
       "      <td>13893340</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28330</th>\n",
       "      <td>5422</td>\n",
       "      <td>21879830</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28331</th>\n",
       "      <td>5422</td>\n",
       "      <td>21880010</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28332</th>\n",
       "      <td>5424</td>\n",
       "      <td>15607495</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28333 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid  timestamp  item_id\n",
       "0       400    5519800      253\n",
       "1       800    5668430     2522\n",
       "2       800   10649375     1290\n",
       "3       800   12673195      145\n",
       "4       800   13626180      628\n",
       "...     ...        ...      ...\n",
       "28328  5420   13508230     2294\n",
       "28329  5420   13893340      495\n",
       "28330  5422   21879830     1154\n",
       "28331  5422   21880010      489\n",
       "28332  5424   15607495     2818\n",
       "\n",
       "[28333 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dislikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc209db",
   "metadata": {},
   "source": [
    "## 3. Create and save user features\n",
    "We do this in train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39be1e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b5ab0fc81e473ab17c3add6fc0e62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff3d119210f4a3cb9c3dc163870400e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641224234ff44ed9bc8c02b5658163fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbb421d77cd42f4b2f0d8032646c7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eac350b1ae64790857a2e21b373588d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95215054d770479e9675fd13f947cf72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b820b8f8ae7f43e19aa6c14e58d9fb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d772772bbb144026b7feb17ae4b0e938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd061609651469d9282cc3c365ef7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887a68c8eb824e5288cb35339cf75e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2960f9a306c497389c692f409df3ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffba1faf9f7440fa947ed156db4cf332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4815da4c645347a7ad287b80443315c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2414b7ca11cb4c96b0dd2859680b14ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users = user_item_data['uid'].unique()\n",
    "\n",
    "# It is HIGHLY recommended to use more than 1 thread per set\n",
    "# You can split the data equally over threads like so:\n",
    "\n",
    "todo_users = [u for u in users if not (Path(\"dataset\")/ \"processed\" / \"users\"/ f\"{u}.pt\").exists()]\n",
    "num_threads = 14\n",
    "k, m = divmod(len(todo_users), num_threads)\n",
    "user_split = [todo_users[i*k + min(i, m) : (i+1)*k + min(i+1, m)] for i in range(num_threads)]\n",
    "\n",
    "\n",
    "\n",
    "# Multithread it to make it somewhat time managable\n",
    "t1 = Thread(target=uf.extract_and_save_features, args=(user_split[0], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t2 = Thread(target=uf.extract_and_save_features, args=(user_split[1], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t3 = Thread(target=uf.extract_and_save_features, args=(user_split[2], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t4 = Thread(target=uf.extract_and_save_features, args=(user_split[3], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t5 = Thread(target=uf.extract_and_save_features, args=(user_split[4], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t6 = Thread(target=uf.extract_and_save_features, args=(user_split[5], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t7 = Thread(target=uf.extract_and_save_features, args=(user_split[6], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t8 = Thread(target=uf.extract_and_save_features, args=(user_split[7], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t9 = Thread(target=uf.extract_and_save_features, args=(user_split[8], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t10 = Thread(target=uf.extract_and_save_features, args=(user_split[9], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t11 = Thread(target=uf.extract_and_save_features, args=(user_split[10], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t12 = Thread(target=uf.extract_and_save_features, args=(user_split[11], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t13 = Thread(target=uf.extract_and_save_features, args=(user_split[12], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "t14 = Thread(target=uf.extract_and_save_features, args=(user_split[13], Path(\"dataset\")/ \"processed\" / \"users\", user_item_data, likes, dislikes))\n",
    "\n",
    "\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "t6.start()\n",
    "t7.start()\n",
    "t8.start()\n",
    "t9.start()\n",
    "t10.start()\n",
    "t11.start()\n",
    "t12.start()\n",
    "t13.start()\n",
    "t14.start()\n",
    "\n",
    "\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "t6.join()\n",
    "t7.join()\n",
    "t8.join()\n",
    "t9.join()\n",
    "t10.join()\n",
    "t11.join()\n",
    "t12.join()\n",
    "t13.join()\n",
    "t14.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1313d22e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_item_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# free up memory, we don't need this anymore\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m user_item_data \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m likes\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m dislikes\n",
      "\u001b[31mNameError\u001b[39m: name 'user_item_data' is not defined"
     ]
    }
   ],
   "source": [
    "# free up memory, we don't need this anymore\n",
    "del user_item_data \n",
    "del likes\n",
    "del dislikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9268a",
   "metadata": {},
   "source": [
    "* 1.1 Kijk of we goeie split krijgen op deze manier\n",
    "* 1.2 Anderrs maak weer 70% 15% 15% split (van git pakken)\n",
    "\n",
    "* 2.0 Hertrain bin_model\n",
    "\n",
    "* evaluate zie whatsapp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888d341",
   "metadata": {},
   "source": [
    "### 3.1: merge the seperate user files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1eabb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71175c3b1f1543a9a4bf58f30197013b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing users:   0%|          | 0/5426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = Path(\"dataset\") / \"processed\" / \"users\"\n",
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "\n",
    "\n",
    "user_feats = []\n",
    "ids = []\n",
    "songids = []\n",
    "embeddings = []\n",
    "labels = []\n",
    "interactions = []\n",
    "\n",
    "\n",
    "files = list(files.glob(\"*.pt\"))\n",
    "\n",
    "for file in progress_bar(files, desc=\"Processing users\"):\n",
    "    data = torch.load(file, map_location=\"cpu\")\n",
    "    f = data['user_feats']         # shape: [N, F]\n",
    "    uid = data['user_ids']        # shape: [N]\n",
    "    sid = data['song_ids']        # shape: [N]\n",
    "    em = data['song_embeds']       # shape: [N, E]\n",
    "    lb = data['labels']            # shape: [N, L]\n",
    "    it = data['interactions'] # shape: [N]\n",
    "\n",
    "\n",
    "    # Slice per user\n",
    "    user_feats.append(f)\n",
    "    ids.append(uid)\n",
    "    songids.append(sid)\n",
    "    embeddings.append(em)\n",
    "    labels.append(lb)\n",
    "    interactions.append(it)\n",
    "\n",
    "\n",
    "user_feats = torch.cat(user_feats, dim=0)\n",
    "ids = torch.cat(ids, dim=0)\n",
    "songids = torch.cat(songids, dim=0)\n",
    "embeddings = torch.cat(embeddings, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "interactions = torch.cat(interactions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ae302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 3142861\n",
      "Number of val samples: 314963\n",
      "Number of test samples: 314963\n"
     ]
    }
   ],
   "source": [
    "# Boolean mask\n",
    "train_mask = interactions == 0        # True where interaction > 0\n",
    "valtest_mask = ~train_mask                 # interaction <= 0\n",
    "\n",
    "# Train \n",
    "train_ufs = user_feats[train_mask]\n",
    "train_uid = ids[train_mask]\n",
    "train_sid = songids[train_mask]\n",
    "train_emb = embeddings[train_mask]\n",
    "train_lab = labels[train_mask]\n",
    "train_int = interactions[train_mask]\n",
    "\n",
    "# Non-positive interactions\n",
    "val_sample_count = 629926//2\n",
    "\n",
    "val_ufs = user_feats[valtest_mask][:val_sample_count]\n",
    "val_uid = ids[valtest_mask][:val_sample_count]\n",
    "val_sid = songids[valtest_mask][:val_sample_count]\n",
    "val_emb = embeddings[valtest_mask][:val_sample_count]\n",
    "val_lab = labels[valtest_mask][:val_sample_count]\n",
    "val_int = interactions[valtest_mask][:val_sample_count]\n",
    "\n",
    "\n",
    "test_ufs = user_feats[valtest_mask][val_sample_count:]\n",
    "test_uid = ids[valtest_mask][val_sample_count:]\n",
    "test_sid = songids[valtest_mask][val_sample_count:]\n",
    "test_emb = embeddings[valtest_mask][val_sample_count:]\n",
    "test_lab = labels[valtest_mask][val_sample_count:]\n",
    "test_int = interactions[valtest_mask][val_sample_count:]\n",
    "\n",
    "combined_ufs = user_feats[valtest_mask]\n",
    "combined_uid = ids[valtest_mask]\n",
    "combined_sid = songids[valtest_mask]\n",
    "combined_emb = embeddings[valtest_mask]\n",
    "combined_lab = labels[valtest_mask]\n",
    "combined_int = interactions[valtest_mask]\n",
    "\n",
    "print(\"Number of train samples:\", train_ufs.shape[0])\n",
    "print(\"Number of val samples:\", val_ufs.shape[0])\n",
    "print(\"Number of test samples:\", test_ufs.shape[0])\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    \"user_feats\":           train_ufs,\n",
    "    \"user_ids\":             train_uid,\n",
    "    \"song_ids\":             train_sid,\n",
    "    \"song_embeds\":          train_emb,\n",
    "    \"labels\":               train_lab,\n",
    "    \"interactions\":         train_int\n",
    "}, Path(\"dataset\") / \"processed\"/ 'train.pt')\n",
    "\n",
    "torch.save({\n",
    "    \"user_feats\":           val_ufs,\n",
    "    \"user_ids\":             val_uid,\n",
    "    \"song_ids\":             val_sid,\n",
    "    \"song_embeds\":          val_emb,\n",
    "    \"labels\":               val_lab,\n",
    "    \"interactions\":         val_int\n",
    "}, Path(\"dataset\") / \"processed\"/ 'val.pt')\n",
    "\n",
    "torch.save({\n",
    "    \"user_feats\":           test_ufs,\n",
    "    \"user_ids\":             test_uid,\n",
    "    \"song_ids\":             test_sid,\n",
    "    \"song_embeds\":          test_emb,\n",
    "    \"labels\":               test_lab,\n",
    "    \"interactions\":         test_int\n",
    "}, Path(\"dataset\") / \"processed\"/ 'test.pt')\n",
    "\n",
    "torch.save({\n",
    "    \"user_feats\":           combined_ufs,\n",
    "    \"user_ids\":             combined_uid,\n",
    "    \"song_ids\":             combined_sid,\n",
    "    \"song_embeds\":          combined_emb,\n",
    "    \"labels\":               combined_lab,\n",
    "    \"interactions\":         combined_int\n",
    "}, Path(\"dataset\") / \"processed\"/ 'combined.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194c838",
   "metadata": {},
   "source": [
    "## 4. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f598ad8",
   "metadata": {},
   "source": [
    "### 4.1 set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d528b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models on: cuda\n"
     ]
    }
   ],
   "source": [
    "import utils.dataset_functions as df\n",
    "import utils.user_features as uf\n",
    "import utils.two_towers as ttn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from threading import Thread\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm as progress_bar\n",
    "\n",
    "\n",
    "(Path(\"dataset\") / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "data_dir = Path(\"dataset\") / \"unprocessed\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "# Dimensions of the tower FFN\n",
    "output_dim      = 16\n",
    "hidden_dim      = 256\n",
    "id_dim          = 16\n",
    "\n",
    "\n",
    "# Training\n",
    "num_epochs      = 60\n",
    "learning_rate   = 1e-3\n",
    "batch_size      = 256\n",
    "patience        = 20\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Training models on:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32021d74",
   "metadata": {},
   "source": [
    "### 4.2 Training our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee37becf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [31/50]\n",
      "early stopped\n"
     ]
    }
   ],
   "source": [
    "models = [\"binary_label\", \"continueous_label\"]\n",
    "\n",
    "for label_id, model_name in enumerate(models):\n",
    "    train_set = df.load_tensor_dataloader(\"train\", Path(\"dataset\")/\"processed\", batch_size, label_id)\n",
    "    val_set = df.load_tensor_dataloader(\"val\", Path(\"dataset\")/\"processed\", batch_size, label_id)\n",
    "\n",
    "\n",
    "    model = ttn.DualAugmentedTwoTower(model_name, hidden_dim, output_dim, id_dim)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    if label_id == 1:\n",
    "        loss = MSELoss()\n",
    "    else:\n",
    "        loss = binary_cross_entropy\n",
    "\n",
    "    ttn.train_model(model, train_set, val_set, optimiser, patience, num_epochs=50, device=device, loss_function=loss)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
