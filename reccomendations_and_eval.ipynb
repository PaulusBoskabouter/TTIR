{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataset_functions as df\n",
    "import utils.user_features as uf\n",
    "import utils.two_towerssimple as ttn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm as progress_bar\n",
    "\n",
    "\n",
    "(Path(\"dataset\") / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "data_dir = Path(\"dataset\") / \"unprocessed\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca260872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataset_functions as df\n",
    "import utils.user_features as uf\n",
    "import utils.two_towerssimple as ttn\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm as progress_bar\n",
    "\n",
    "\n",
    "(Path(\"dataset\") / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "data_dir = Path(\"dataset\") / \"unprocessed\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "# Input dimensions\n",
    "user_dim        = 5 \n",
    "item_dim        = 128\n",
    "aug_dim         = 64\n",
    "\n",
    "# Dimensions of the tower FFN\n",
    "hidden_dim      = 256\n",
    "embed_dim       = 64\n",
    "id_dim          = 64\n",
    "\n",
    "# lambda1 for loss_u & lambda2 for loss_V\n",
    "lambda1         = 1.0\n",
    "lambda2         = 1.0\n",
    "\n",
    "# Uhh\n",
    "batch_size = 128\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Training models on:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e5ede",
   "metadata": {},
   "source": [
    "### Recommendations & Evaluation\n",
    "Ik weet niet precies hoe alles precies in elkaar steekt dus ik schrijf ff een skelet en dan moet je maar ff kijken of dingen kloppen.\n",
    "\n",
    "Dit zijn de stappen die ik probeer te zetten:\n",
    "- Lijst van nummers inladen\n",
    "- Lijst van users inladen\n",
    "- modellen inladen\n",
    "- per model\n",
    "  - bereken song embeddings (yv)\n",
    "  - bereken user embeddings (uv)\n",
    "  - maak index voor reccomendations\n",
    "  - per user\n",
    "    - maak recommendations\n",
    "    - voeg recommendations en test set (van die user) samen\n",
    "    - reken dot-product uit per query recommendation pair\n",
    "    - rerank op dot-product\n",
    "    - beoordeel rankings (op reinforcement signal / like-dislikes\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab5465",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m models = [\u001b[33m\"\u001b[39m\u001b[33minteractions_model\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmultiple_listens_model\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpct_100_model\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpct_80_model\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label_id, model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     test_set = df.load_tensor_dataloader(\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m, Path(\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m)/\u001b[33m\"\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m\"\u001b[39m, batch_size, label_id)\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[32m     10\u001b[39m     model = ttn.DualAugmentedTwoTower(model_name, user_dim, item_dim, hidden_dim, aug_dim, id_dim)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "songs = None # Lijst van nummers inladen (los van users) (features + IDs)\n",
    "users = None # Lijst van users inladen (los van users) (features + IDs)\n",
    "\n",
    "models = [\"interactions_model\", \"multiple_listens_model\", \"pct_100_model\", \"pct_80_model\"]\n",
    "\n",
    "for label_id, model_name in enumerate(models):\n",
    "    test_set = df.load_tensor_dataloader(\"val\", Path(\"dataset\")/\"processed\", batch_size, label_id)\n",
    "\n",
    "    # Load model\n",
    "    model = ttn.DualAugmentedTwoTower(model_name, user_dim, item_dim, hidden_dim, aug_dim, id_dim)\n",
    "    model.load(Path(\"models\"))\n",
    "\n",
    "    # Create song embeddings \n",
    "    # (Ik weet ff niet hoe de columns heten, dubbelcheck dit ff)\n",
    "    songs['yv'] = songs['song_features', 'song_id'].apply(lambda song: model.yv(song['song_features'], song['song_id']), axis = 1)\n",
    "\n",
    "    # Create user embeddings\n",
    "    # (Ik weet ff niet hoe de columns heten, dubbelcheck dit ff)\n",
    "    users['uv'] = users['user_features', 'user_id'].apply(lambda user: model.yv(user['user_features'], user['user_id']), axis = 1)\n",
    "    \n",
    "    # Create index for reccommendations\n",
    "    model.create_index(songs['yv'].to_numpy())\n",
    "\n",
    "    # Metric voor alle recommendations\n",
    "    RS_scores = []  # Reinforcement Signal\n",
    "    LDL_scores = [] # Like-DisLike\n",
    "\n",
    "    # Loop users\n",
    "    for index, user in users.iterrows:\n",
    "\n",
    "        # Get user embedding\n",
    "        query = user['uv']\n",
    "\n",
    "        # Make 25 recommendations\n",
    "        indices, distances = model.recommendations(query, 25)\n",
    "        recommendations = songs.iloc[indices]\n",
    "\n",
    "        # Merge recommendations with the users test-split\n",
    "        \n",
    "        # recommendations = ... (add test songs here)\n",
    "\n",
    "        # Calculate scores (dot product with query)\n",
    "        recommendations['score'] = recommendations['yv'].apply(lambda yv: (query * yv).sum())\n",
    "\n",
    "        # Re-rank\n",
    "        ranking = recommendations.sort_values(by = 'score')\n",
    "\n",
    "        # Evaluate ranking\n",
    "        # Weet nog niet hoe. We moeten iig de like/dislikes mergen met de ranking en daar iets van een score uit halen\n",
    "        # Ook kunnen we nog de reinforcement signal mergen en daar Froukjes metrics op los laten\n",
    "        \n",
    "        # RS_score = ...\n",
    "        # LDL_score = ...\n",
    "\n",
    "        # RS_scores.append(RS_score)\n",
    "        # LDL_scores.append(LDL_score)\n",
    "\n",
    "    # Aggregate scores (average?)\n",
    "    RS_score = np.mean(RS_scores)\n",
    "    LDL_score = np.mean(LDL_scores)\n",
    "    print(f'{model_name}: RS = {RS_score}, LDL = {LDL_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
