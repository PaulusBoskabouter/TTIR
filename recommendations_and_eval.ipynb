{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8fa5833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models on: cuda\n"
     ]
    }
   ],
   "source": [
    "import utils.dataset_functions as df\n",
    "import utils.user_features as uf\n",
    "import utils.two_towers as ttn\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import faiss\n",
    "\n",
    "# Dimensions of the tower FFN\n",
    "output_dim      = 16\n",
    "hidden_dim      = 256\n",
    "id_dim          = 16\n",
    "\n",
    "\n",
    "# Training\n",
    "num_epochs      = 50\n",
    "learning_rate   = 1e-3\n",
    "batch_size      = 256\n",
    "patience        = 5\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Training models on:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e5ede",
   "metadata": {},
   "source": [
    "### Recommendations & Evaluation\n",
    "Ik weet niet precies hoe alles precies in elkaar steekt dus ik schrijf ff een skelet en dan moet je maar ff kijken of dingen kloppen.\n",
    "\n",
    "Dit zijn de stappen die ik probeer te zetten:\n",
    "- Lijst van nummers inladen\n",
    "- Lijst van users inladen\n",
    "- modellen inladen\n",
    "- per model\n",
    "  - bereken song embeddings (yv)\n",
    "  - bereken user embeddings (uv)\n",
    "  - maak index voor reccomendations\n",
    "  - per user\n",
    "    - maak recommendations\n",
    "    - voeg recommendations en test set (van die user) samen\n",
    "    - reken dot-product uit per query recommendation pair\n",
    "    - rerank op dot-product\n",
    "    - beoordeel rankings (op reinforcement signal / like-dislikes\n",
    "\n",
    "\n",
    "\n",
    "Per user\n",
    "\n",
    "1. eerste sample uit de testset wordt gebruikt\n",
    "2. De rest vd samples zijn voor de ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_data = pd.read_csv(Path(\"dataset\") / \"processed\" / \"merged.csv\", index_col=False).drop([\"normalized_embed\"], axis=1)\n",
    "songs = torch.load(Path(\"dataset\") / \"processed\" / \"song_subset.pt\")\n",
    "binary_embeddings = songs['binary']\n",
    "non_binary_embeddings = songs['continueous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "663b34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_seen = {} # user: [num_ids of songs already listened to]\n",
    "\n",
    "for u in user_item_data['uid'].unique():\n",
    "    a = user_item_data[(user_item_data['uid'] == u)]\n",
    "    already_seen[u] = a[0:int(0.7 * len(a))]['item_id'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab5465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3192\n"
     ]
    }
   ],
   "source": [
    "binary_model = model = ttn.DualAugmentedTwoTower(\"binary_label\", hidden_dim, output_dim, id_dim)\n",
    "binary_model.load(Path(\"models\")/ \"binary_label.pt\")\n",
    "non_binary_model = ttn.DualAugmentedTwoTower(\"continueous_label\", hidden_dim, output_dim, id_dim)\n",
    "non_binary_model.load(Path(\"models\")/ \"continueous_label.pt\")\n",
    "\n",
    "test_set = df.load_tensor_dataloader(\"val\", Path(\"dataset\")/\"processed\", 1, label_id=2)\n",
    "\n",
    "\n",
    "\n",
    "# Create user embeddings\n",
    "# (Ik weet ff niet hoe de columns heten, dubbelcheck dit ff)\n",
    "\n",
    "users = {}\n",
    "for user_features, song_embedding, label, interaction, user_id, song_id in test_set:\n",
    "    if song_id.item() not in already_seen[user_id.item()]:\n",
    "        if users.get(user_id.item()) is None:\n",
    "            if len(users) > 5:\n",
    "                break\n",
    "            users[user_id.item()] = {}\n",
    "\n",
    "            users[user_id.item()]['user_embed_bin'] = binary_model.user_pass(user_features, user_id).detach().squeeze(0)\n",
    "            users[user_id.item()]['user_embed_nbin'] = non_binary_model.user_pass(user_features, user_id).detach().squeeze(0)\n",
    "\n",
    "            users[user_id.item()]['user_interact_ratio'] = user_features.squeeze(0)[4].item()\n",
    "            users[user_id.item()]['song_data'] = {}\n",
    "\n",
    "        \n",
    "        else:\n",
    "            users[user_id.item()]['song_data'][song_id.item()] = (label.squeeze(0).tolist(), interaction.item())\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "recommendations = {}\n",
    "non_binary_index = np.array([i.tolist() for i in non_binary_embeddings.values()])\n",
    "binary_index = np.array([i.tolist() for i in binary_embeddings.values()])\n",
    "\n",
    "print(len(non_binary_index))\n",
    "non_binary_model.create_index(non_binary_index)\n",
    "binary_model.create_index(binary_index)\n",
    "for u in users.keys():\n",
    "    \n",
    "    \n",
    "    user = users[u]\n",
    "    \n",
    "    \n",
    "\n",
    "    nbin_query = user[\"user_embed_nbin\"][np.newaxis, :]\n",
    "    nbin_distances, nbin_indices = non_binary_model.recommendations(nbin_query, 100)\n",
    "\n",
    "    bin_query = user[\"user_embed_bin\"][np.newaxis, :]\n",
    "    bin_distances, bin_indices = binary_model.recommendations(bin_query, 100)\n",
    "    \n",
    "    \n",
    "    nbin_score = [(nbin_query * non_binary_embeddings[e]).sum() for e in nbin_indices[0]]\n",
    "    bin_score = [(bin_query * binary_embeddings[e]).sum() for e in bin_indices[0]]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    recommendations[u] = {\n",
    "        \"non_binary\": (nbin_score, nbin_indices, nbin_distances),\n",
    "        \"binary\": (bin_score, bin_indices, bin_distances)\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    # TODO\n",
    "    # 1. calculate scores for all the test set songs bin and nbin\n",
    "    # 2. Create dataframe of the output.\n",
    "    # 3. Do the metrics things\n",
    "\n",
    "    # indices, distance = binary_model.recommendations(user['user_embed_bin'], 25)\n",
    "\n",
    "    # users['yu'] = users['user_features', 'user_id'].apply(lambda user: model.user_pass(user['user_features'], user['user_id']), axis = 1)\n",
    "    \n",
    "    # # Create index for reccommendations\n",
    "    # model.create_index(songs['ys'].to_numpy())\n",
    "\n",
    "    # # Metric voor alle recommendations\n",
    "    # RS_scores = []  # Reinforcement Signal\n",
    "    # LDL_scores = [] # Like-DisLike\n",
    "\n",
    "    # # Loop users\n",
    "    # for index, user in users.iterrows:\n",
    "\n",
    "    #     # Get user embedding\n",
    "    #     query = user['yu']\n",
    "\n",
    "    #     # Make 25 recommendations\n",
    "    #     indices, distances = model.recommendations(query, 25)\n",
    "    #     recommendations = songs.iloc[indices]\n",
    "\n",
    "    #     # Merge recommendations with the users test-split\n",
    "        \n",
    "    #     # recommendations = ... (add test songs here)\n",
    "\n",
    "    #     # Calculate scores (dot product with query)\n",
    "    #     recommendations['score'] = recommendations['ys'].apply(lambda yv: (query * yv).sum())\n",
    "\n",
    "    #     # Re-rank\n",
    "    #     ranking = recommendations.sort_values(by = 'score')\n",
    "\n",
    "    #     # Evaluate ranking\n",
    "    #     # Weet nog niet hoe. We moeten iig de like/dislikes mergen met de ranking en daar iets van een score uit halen\n",
    "    #     # Ook kunnen we nog de reinforcement signal mergen en daar Froukjes metrics op los laten\n",
    "        \n",
    "    #     # RS_score = ...\n",
    "    #     # LDL_score = ...\n",
    "\n",
    "    #     # RS_scores.append(RS_score)\n",
    "    #     # LDL_scores.append(LDL_score)\n",
    "\n",
    "    # # Aggregate scores (average?)\n",
    "    # RS_score = np.mean(RS_scores)\n",
    "    # LDL_score = np.mean(LDL_scores)\n",
    "    # print(f'{model_name}: RS = {RS_score}, LDL = {LDL_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6249fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
